## B站一面

提前10分钟就点进去了面试链接，虽然之前面了很多家公司了，但是对面是b站，内心还是有点紧张。很快，一面面试官也进来了，比原本约定的时间提早了5分钟就开始了。面试官可能刚面完别人，看起来有点疲惫的样子。面试官让我先做个自我介绍，自我介绍之前都已经倒背如流了，结果因为有点紧张，最后还是即兴发挥了，不过也还不错，比预想的要好。其实自我介绍说完就已经没那么紧张了，整个人都放松了下来，面试官人很不错，说话很温柔，会耐心听我讲完。下面就是一面的面试题了。

#### 1. 介绍一下git的常见指令


1.  初始化新仓库：

    ```
    git init
    ```

    用于在当前目录下创建一个新的Git仓库。

2.  添加远程仓库：

    ```
    git remote add origin <repository-url>
    ```

    将本地仓库关联到远程仓库，`origin` 是远程仓库的默认名称，`<repository-url>` 是远程仓库的URL。

3.  克隆仓库：

    ```
    git clone <repository-url>
    ```

    从远程仓库克隆一个全新的本地仓库副本。

4.  添加文件到暂存区：

    ```
    git add <file>
    ```

    或者一次性添加所有改动

    ```
    git add .
    ```

    将指定文件或所有改动过的文件添加到暂存区，准备提交。

5.  提交更改：

    ```
    git commit -m "<commit-message>"
    ```

    将暂存区的所有内容提交到本地仓库，并附带一条提交消息。

6.  查看提交历史：

    ```
    git log
    ```

    显示提交历史记录。

7.  拉取远程仓库的最新变更：

    ```
    git pull
    ```

    从远程仓库获取并合并最新的提交到本地分支。

8.  推送本地提交到远程仓库：

    ```
    git push origin <branch-name>
    ```

    将本地分支的提交推送到远程仓库的指定分支。

9.  切换分支：

    ```
    git checkout <branch-name>
    ```

    切换到指定分支。

10.  创建新分支并切换到该分支：

    ```
    git checkout -b <new-branch-name>
    ```

11.  合并分支：

    ```
    git merge <branch-name>
    ```

    将指定分支的最新提交合并到当前所在分支。

12.  删除分支：

    ```
    git branch -d <branch-name>
    ```

    删除已合并的本地分支；若要强制删除未合并的分支：

    ```
    git branch -D <branch-name>
    ```

13.  解决合并冲突： 在合并或拉取时出现冲突时，解决冲突后：

    ```
    git add <conflicted-file>
    git commit -m "Resolved merge conflict"
    ```

14.  撤销工作区的修改：

    ```
    git checkout -- <file>
    ```

    丢弃工作区对指定文件的修改（未add到暂存区的改动）。

15.  撤销暂存区的修改：

    ```
    git reset <file>
    ```

    移除暂存区中指定文件的改动，但保留工作区的改动。

16.  强制推送：

    ```
    git push origin <branch-name> --force
    ```

    强制覆盖远程分支（谨慎使用，可能导致远程仓库丢失提交）。
    
之后复盘面试的时候，社长说还有一个很重要的git指令没说 -- git rebase

老实说之前确实没怎么听过这个指令，又学到新知识了，不错 ^.^。下面是网上搜来的一些关于git rebase的一些知识。

17. git rebase
> 
> - 主要作用用来改变历史，尤其是当你想将一系列提交合并、重新排序或在无冲突的基础上应用到另一个分支时。下面是一些基础用法：
> 
>     - **1. 变基到上游分支**
> 
>         - git rebase [upstream-branch]    
> 
>         作用：将当前分支的所有未合并提交放置在 `[upstream-branch]` 的顶部，从而让本地分支与上游分支保持一致，并且保持提交历史线性。
>         
>     - **2. 交互式变基(合并提交)**
> 
>         - git rebase -i  [base-branch]
> 
>         这将启动一个交互式的编辑器，允许你重新排列提交、合并连续的提交、修改提交信息等。`-i` 表示 interactive（交互式）。
> 
>         在编辑器中，你可以对每一行代表的提交进行操作：
> 
>         -   `pick` 保留该提交（默认）
>         -   `squash` 将该提交与其前一个提交合并
>         -   `fixup` 类似于 `squash`，但不保留合并时的提交消息，使用前一个提交的消息
>         -   `reword` 修改该提交的注释信息
>         -   `edit` 在变基过程中暂停，让你有机会修改提交内容或注释
>         -   `drop` 删除该提交
> 
>     - **3. 变基并解决冲突**
>         - 如果在变基过程中遇到冲突，你需要手动解决冲突，然后执行：
> 
>         1. git add [resolved-files]
>         2. git rebase --continue
> 
>         - 若想放弃变基并返回到变基前的状态：
> 
>         1. git rebase --abort
> 
>     - **4. 变基到指定提交**
> 
>          - git rebase [commit-hash]
> 
>          将当前分支的头部移动到指定提交之后，并将所有未合并的提交放在指定提交之上。
>          
>     - 5. 变基并保留分支指针不动
> 
>         - git rebase --onto [new-base] [old-base]
> 
>         这个命令会将 `<old-base>` 与当前分支之间的所有提交移到 `<new-base>` 分支上，而当前分支的指针仍指向原来的最后一个提交，这时需要手动更新分支指针。
>         
> 
> 注意：`git rebase` 会改变提交历史，因此在多人协作的环境中应当谨慎使用，特别是不要在已被共享的分支上随意执行 `git rebase`，因为它可能导致其他人难以合并你的更改。在公开分支上，一般建议使用 `git merge` 来合并分支，以保持提交历史的完整性和可追溯性。

#### 2. == 和 === 的区别，为什么 [] == ![] 为 true

面试常考题了，涉及到了类型转换，其实理清楚之后就不难了，我当时回答的也很流畅，这里我就直接引用我社团同学的文章了，感兴趣的可以去看看 -- [面试官 ：[] == ! [] 为什么返回 true ？](https://juejin.cn/post/7308536984028856346)

#### 3. ref和reactive的区别

大厂面试，你要是只是简单聊聊这两者的区别，肯定是不够的。我感觉更重要的是自己要懂得拓展来讲，我面试的时候，先聊了聊他们两者的区别，自然而然就会聊到Vue的响应式，于是这个时候你自己先把响应式的原理给面试官讲一遍，面试官对你的第一印象就更好。感觉面试的应试技巧是很重要的。

好，扯了点题外话，下面开始回答上面这个问题。

先聊区别：

- 1. **所包装的类型不同:** ref可以用来包装原始数据类型和引用数据类型，也就是说它可以将任何类型的值都变成响应式的，但是使用时需要带上.value。而reactive只能用来包装对象。

    - 既然聊到了这里，就可以给面试官讲一下为什么它们所包装的类型不同，聊一聊reactive基于ES6新增的proxy对数据进行拦截，因为proxy是接受对象作为参数，所以reactive用来包装对象。可以和面试官聊一聊你说你之前有研究过ref和reactive的源码，所以了解源码还是很重要的。

- 2. **响应式原理不同:**  ref 内部使用 RefImpl 对象包裹原始值，通过 .value 访问时会触发依赖收集和更新通知。reactive 则是利用 ES6 的 Proxy 对象，对整个对象的属性读写进行拦截，实现了深度响应式。

    - 都聊到这里了，再和面试官主动讲一讲如何他们两个是如何实现响应式的，讲解一下副作用函数收集，和副作用函数触发。再聊一聊vue2和vue3响应式的区别，为什么vue3的响应式更好等等问题。面试官对你的好感又会上一个台阶。


其实区别大致就这两个，真正研究了一点Vue的源码，这种题目回答起来应该是得心应手。

#### 4. 生命周期相关

- 父子组件都有`created`和`mounted`，问父组件的`created`和`mounted`和子组件的`created`以及`mounted`的它们四个的执行顺序

在 Vue.js 中，父子组件的生命周期钩子执行顺序如下：

1.  **父组件生命周期钩子执行顺序**：

    -   `beforeCreate`
    -   `created`
    -   `beforeMount`
    -   **子组件开始执行生命周期钩子**
    -   子组件 `beforeCreate`
    -   子组件 `created`
    -   子组件 `beforeMount`
    -   子组件 `mounted`
    -   **子组件的 `mounted` 钩子全部执行完毕后**
    -   父组件 `mounted`

总结来说，父组件的 `created` 钩子在子组件的 `created` 钩子之前执行，而父组件的 `mounted` 钩子会在所有子组件的 `mounted` 钩子执行完毕后执行。这有助于确保父组件的 DOM 已经准备就绪，然后再执行子组件的 DOM 挂载相关的逻辑。

#### 5. Vuex和Pinia的区别，使用感受

讲了一下Vuex的使用方法和Pinia的方法，以及Vuex主要是在Vue2中使用，和Vue2的选项式api符合，当然Vue3也可以用，Pinia主要在Vue3中使用，与Vue3的组合式API符合。Vuex的结构更加严谨，更适合大型复杂应用开发，有一套成熟完善的生态系统，保证了状态管理的严格和可控性。而Pinia更适合中小型项目，对于那些追求轻量级解决方案的项目更加友好。个人平时都有用，主要是用Pinia，因为主要写的是Vue3，Pinia更符合Vue3的组合式API书写。

#### 6. 项目中用到的持久化储存如何实现

第一家面的公司已经问过了，果然写在简历里就容易被问到，这里就不再列一遍了，上文有介绍过。

#### 7. 你平时如何调试自己的代码的

1.  **浏览器开发者工具**：

    -   **Chrome DevTools**、**Firefox Developer Tools**、**Microsoft Edge DevTools** 等现代浏览器均内置了强大的开发者工具，通过它们可以查看和修改DOM结构、CSS样式、JavaScript代码，并且可以实时调试代码。
    -   **源代码查看与编辑**：在 Sources 或 Debugger 面板中，可以查看并编辑网页加载的JavaScript文件，同时可以设置断点、逐行执行、查看变量值等。
    -   **Console控制台**：使用 `console.log()`、`console.error()`、`console.warn()` 等方法输出调试信息，查看变量值、函数调用结果等。
    -   **Elements面板**：可以检查和修改DOM结构，查看CSS样式及其计算值，以及布局和尺寸信息。
    -   **Network面板**：分析HTTP请求和响应，调试网络相关问题。
    -   **Memory面板**：检查内存使用情况，寻找内存泄漏等问题。

2.  **断点调试**：

    -   在代码中设置断点，浏览器在执行到断点时会暂停，此时可以查看当前作用域下的变量值、逐步执行代码（Step Into、Step Over、Step Out）。

3.  **Source Maps**：

    -   对于压缩或混淆过的代码，通过Source Map可以将浏览器开发者工具中的源代码映射到未经压缩的实际源代码，方便调试。

4.  **移动端和内置浏览器调试**：

    -   对于移动端应用内的网页，可以使用设备的USB连接电脑，并开启远程调试功能（如Chrome DevTools的Remote Devices或Safari的Web Inspector）。
    -   第三方应用内置浏览器可通过相应工具或开发文档提供的方法接入调试。

5. **Vue Devtools**：

    - Vue Devtools 不仅可以提供可视化的组件树结构展示，还允许开发者查看组件状态，监控数据变化，时间旅行调试，组件快照等等。

6.  **在线调试**：

    -   对于线上代码，如果开启了Source Maps，并且服务端支持，可以通过浏览器开发者工具远程调试线上代码，或通过Browsersync等工具同步本地代码到线上环境进行调试。


#### 8. 如何调试网络请求

这个问题是前一个问题的相关问题，由于前一个问题没回答到这个，面试官又追问了这个问题


- **1. 使用Chrome DevTools**:也就是浏览器右键，点击检查，来到网络，在这里可以查看一些网络请求和响应信息。

    - 光回答这些可能太单调了，还是那句话，自己拓展到其他领域讲讲，比如我就给面试官主动讲了讲请求头有哪些东西，响应头有哪些东西，这里可以聊很多东西，比如根据请求头中的Cookie字段我们可以讲一讲jwt鉴权，但是我没讲很多，就说了一下项目中使用了token，以及为什么请求头中会携带上token。果不其然，之后面试官就要我聊一聊jwt鉴权，早就准备好了，所以十分轻松就说完了。在讲到Connection字段又和面试官聊了聊长连接。讲这些的时候，时间也正在飞速流逝，但这一切的前提是面试官不会主动打断你说话哦。

-**2. Postman模拟请求**：利用第三方工具模拟请求，测试接口。


#### 9. 介绍一下常用的状态码

很常规的八股文，不过讲的时候要有顺序，从1xx 依次讲到 5xx，并且介绍一下这些状态码的应用场景就行

1.  **1**xx（信息提示）：

    -   **100 Continue**：继续。客户端应当继续发送请求的剩余部分，如果请求已经完成，则忽略此响应。
    -   **101 Switching Protocols**：协议切换。服务器同意客户端的协议切换请求。

2.  **2**xx（成功）：

    -   **200 OK**：请求成功，请求的数据在响应正文中返回。
    -   **201 Created**：请求成功并且服务器创建了新的资源。
    -   **202 Accepted**：服务器已接受请求，但尚未处理完成。

3.  **3**xx（重定向）：

    -   **301 Moved Permanently**：永久重定向，请求的资源已永久转移到新的URI。
    -   **302 Found**（有时是303 See Other或307 Temporary Redirect）：临时重定向，请求的资源临时位于新的URL上。
    -   **304 Not Modified**：请求的资源未修改过，客户端可以继续使用缓存的版本。

4.  **4**xx（客户端错误）：

    -   **400 Bad Request**：客户端请求有误，服务器无法理解。
    -   **401 Unauthorized**：请求未经授权，需要身份验证。
    -   **403 Forbidden**：服务器理解请求但拒绝执行。
    -   **404 Not Found**：服务器找不到请求的资源。
    -   **405 Method Not Allowed**：服务器不支持请求所用的HTTP方法。

5.  **5**xx（服务器错误）：

    -   **500 Internal Server Error**：服务器遇到了意外情况，无法完成请求。
    -   **502 Bad Gateway**：服务器作为网关或代理时，收到了无效响应。
    -   **503 Service Unavailable**：服务器暂时无法处理请求，通常由于服务器过载或维护。
    -   **504 Gateway Timeout**：服务器作为网关或代理时，未能及时从上游服务器（如应用服务器）获取响应。

#### 10. 聊一聊JWT鉴权

之前自己和面试官主动说了token，果然就被问到了更细节的东西。

先介绍了一下JWT的结构，主要由下面三部分组成：

**1. Header（头部）** ： 包含JWT元数据，通常包括令牌类型（typ，固定为"JWT"）和签名算法（alg，如HS256、RS256等）。

**2. Payload（载荷）** ： 包含实际的声明，可以是有关用户的任何信息，如用户ID、用户名、角色、过期时间等。这些声明可以分为三种类型：

-   **Registered Claims**: 如`exp`（过期时间）、`iat`（发行时间）、`sub`（主题）等。
-   **Public Claims**: 由IANA注册或者在特定命名空间下的自定义声明。
-   **Private Claims**: 应用程序专用的声明。

**3. Signature（签名）** ： 根据前面两部分（Header和Payload）以及一个密钥（secret key）生成的签名，用于验证数据完整性，确保JWT未被篡改。签名算法可以是HMAC SHA家族（如HS256、HS384、HS512）或者RSA和ECDSA家族（如RS256、ES256等）。

然后讲了一下JWT的工作流程。

**JWT的工作流程：**

1.  **签发Token**： 用户登录时，服务端验证用户凭证（用户名/密码等），验证成功后，服务端生成一个包含用户相关信息的JWT，通过Header指定的签名算法加密生成签名，并将整个JWT返回给客户端。
2.  **客户端存储和使用Token**： 客户端收到JWT后，通常将其存储在Cookie、LocalStorage或SessionStorage中。每次发起请求时，将JWT放入HTTP请求头（如`Authorization`头，格式通常为`Bearer <token>`）中。
3.  **服务端验证Token**： 服务端在接收到带有JWT的请求后，通过Header中的签名算法和事先知道的密钥对JWT进行校验。如果校验通过，则认为客户端持有有效的身份凭证，从而允许访问受保护的资源。

然后介绍了我如何在项目中用的，这里我直接截取我项目中的核心代码了：

**前端：**

- 请求拦截：

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8a2226e953694d45a13c8e493e3a313e~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=724&h=262&s=16591&e=png&b=252a2f)

- 前端登录，存放token：


```
 if(res.status == 200) {
    // 保存用户信息
    localStorage.setItem('token',res.token)
    showSuccessToast('登录成功')

    // 1s后跳转页面
    setTimeout(() =>{
      router.push('/cost') 
    },1500)
  }else{
    showSuccessToast(res.msg)
  }
```

后端：

- 引入jsonwebtoken，手写生成token函数sign

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ed0109ed5a1b49efa7356ee3e33ea2f1~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=709&h=216&s=16353&e=png&b=24292e)

- 后端验证token函数verify


![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7aa7e55c74214e8595c02a7d8db96fe7~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=742&h=644&s=42936&e=png&b=24292e)

上述两个函数拿到定义接口的地方去用：

- 登录接口：


![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3a478a621ce14c4b99d57b8d7f97ffbf~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=882&h=649&s=48453&e=png&b=24292e)

- 示例：对记账接口进行限制


![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/76acfa2a1014484b986971ce3635f4a0~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1087&h=426&s=49341&e=png&b=252a2f)

注意，这里是传入函数，不要调用！

#### 11. 介绍一下Node.js中的流

- 流是一个核心概念，用于有效地处理数据流，特别是针对大容量数据时，能够避免一次性加载所有数据到内存中带来的性能问题。流是基于事件驱动的API设计，允许开发者以连续的小块（chunk）来读取或写入数据，而不是直接操作完整的数据集合。

关于Node.js中流的分类主要为下面几种：

1.  **可读流** ：

    -   可读流是从各种数据源（如文件、网络连接、进程输出等）逐步读取数据的抽象接口。
    -   提供了多个事件，比如 `data` 事件会在每次有新数据块可用时触发，`end` 事件在数据读取完毕时触发。
    -   可以通过`.read()`方法或监听事件来获取数据。

2.  **可写流** ：

    -   可写流用于将数据逐步写入目的地，如文件、网络连接或进程输入等。
    -   提供了`write()`方法来写入数据块，以及`end()`方法来标记写入结束。
    -   当缓冲区满或者流关闭时，会触发相应的事件，如`drain`、`finish`和`close`。

3.  **可读写流** ：

    -   这类流同时实现了可读和可写的特性，例如TCP套接字既可以读取也可以写入数据。
    -   具备上述可读和可写流的所有功能。

4.  **转换流** ：

    -   转换流是在读取数据的同时对其进行处理，并将处理过的数据写入到下游的流。
    -   在读取数据的过程中执行某种中间操作，如压缩、解压、加密或解密等。

Node.js中流处理的.pipe()方法，是流的核心功能之一，它用于将一个流自动连接到另一个流，形成一个数据处理管道，这样数据就会从一个流自动流向下一个，简化了数据流的传递过程，并且在整个过程中都遵循“流”的理念，即数据按需逐步处理，而非一次性全部处理。

也就是说，Node.js中的流极大地提高了在内存受限环境下的数据处理能力，尤其是对于大规模I/O密集型任务，提供了更加高效和灵活的解决方案。

由于前面几个问题我拓展开来聊了，占用了比较多的时间，最后就考了个算法题，如下：


```
const tree = {
  val:1,
  children: [
      {
          val:2,
          children: [
              {
                  val:3,
                  children:[
                      {
                          val:4,
                          children:[]
                      }
                  ]
              }
          ]
      },
      {
          val:5,
          children: [
              {
                  val:6,
                  children:[]
              },
              {
                  val:7,
                  children:[]
              }
          ]
      }
  ]
}
```

问: 求该树的最大深度

很常规的一道算法题，力扣上也有类似的题目。

解法：


```
function maxLevel(root) {
  let level = 0;

  function dfs(root, l) {
    level = Math.max(level, l);

    for (let child of root.children) {
      dfs(child, l + 1);
    }
  }

  dfs(root, 1);

  return level;
}
```


前面回答的时间比较久，到这已经快一个小时了，然后后面就是问了一些面试官关于前端学习的建议，面试官给的建议就是对待事情保持好奇心吧，沟通能力和逻辑思维能力有时候比目前的实力更重要，毕竟是实习生，还年轻，以后有机会可以学。嗯 一面记忆中大概就这些了。

一面最后面试官已经口头上说了一面肯定是给过的，然后第二天下午就约了二面，时间在周四下午，还有两天时间备战...